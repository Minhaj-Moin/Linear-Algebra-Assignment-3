\documentclass[12pt,a4paper]{article}
\usepackage[export]{adjustbox}
\usepackage[utf8]{inputenc}
\usepackage[explicit]{titlesec}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\usepackage{amsmath}   
\usepackage{amssymb}
\usepackage{wasysym}
\usepackage[a4paper, top=0.8in, right=0.3in,left=0.3in,bottom=0.8in]{geometry}
\usepackage{graphicx} %package to manage images
\usepackage[rightcaption]{sidecap}
\usepackage{wrapfig}
% \titleformat{\section}{\normalfont\Large\bfseries}{}{0em}{#1\ \thesection}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{fontspec}
\usepackage{fancyhdr}
\usepackage{standalone}
\usepackage{cancel}
\newcommand{\mat}[1]{\boldsymbol { \mathsf{#1}} }
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
\usepackage[all]{hypcap}
\usepackage{amsfonts}
\usepackage{mdframed}
\usepackage{lastpage}
% \usepackage{tcolorbox}
\usepackage{enumitem}
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\footrulewidth}{0.4pt}
\setlength\headheight{15pt}
\fancyhead[L]{Linear Algebra}
\fancyhead[R]{Assignment 3}
\fancyfoot[R]{Page \thepage\ of \pageref{LastPage}}
\fancyhead[C]{hm02896}

\usepackage{pgf}
\usepackage{pgfpages}





% \pgfpagesdeclarelayout{boxed}
% {
%   \edef\pgfpageoptionborder{0pt}
% }
% {
%   \pgfpagesphysicalpageoptions
%   {%
%     logical pages=1,%
%   }
%   \pgfpageslogicalpageoptions{1}
%   {
%     border code=\pgfsetlinewidth{1pt}\pgfstroke,%
%     border shrink=\pgfpageoptionborder,%
%     resized width=.95\pgfphysicalwidth,%
%     resized height=.95\pgfphysicalheight,%
%     center=\pgfpoint{.5\pgfphysicalwidth}{.5\pgfphysicalheight}%
%   }%
% }

% \pgfpagesuselayout{boxed}


\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}
\setcounter{secnumdepth}{5}

\pgfplotsset{compat=1.15}
\pgfplotsset{
colormap={b}{gray(0cm)=(0); gray(1cm)=(0.8)}
}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.7,0.7,0.7}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.994,0.994,0.994}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle= \ttfamily\scriptsize,
    breakatwhitespace=false,
    frame=topline;
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,               
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}

\title{Linear Algebra Assignment 3}
\author{hm02896 \\ Section L1}
\date{\today}


\begin{document}
% \vspace{10cm}

% \begin{titlepage}
% \vspace*{3cm}
% \begin{center}
% \Huge {MATH 205 : Linear Algebra \\ Assignment \#2} 
% \end{center}
% \vspace{2cm} 
% \begin{center} 
% \Large {hm02896} \\[3pt]
% Section L1 \\ [1cm] 
% \today
% \end{center}

% \vspace{4cm}
% \tableofcontents
% \end{titlepage}

\maketitle

\thispagestyle{fancy}

\section{Question}

\subsection{Part A}

The Potential Energies of the Springs can be written as
$\frac{1}{2}kw_2^2 \text{ and } \frac{1}{2}kw_1^2 \text{ for the two springs}$\\
They'll be balanced by the work done by the reactionary forces, which are $Q_1w_1$  and  $Q_2w_2$, and the input work, which is $Py$.\\
The Potential Energy $\Pi$ can then be written as

$$\Pi = \frac{1}{2}kw_1^2 + \frac{1}{2}kw_2^2 - (Q_1w_1 + Q_2w_2) - Py$$

Now, given from the question hint, we put the value of $y$, to get:

$$\Pi = \frac{1}{2}kw_1^2 + \frac{1}{2}kw_2^2 - (Q_1w_1 + Q_2w_2) -
P\left(\frac{w_1^2 + w_1^2 - w_1w_2}{a}\right)$$

$$\Pi = \frac{w_1^2}{2}\left(k-\frac{2P}{a}\right) + \frac{w_2^2}{2}\left(k-\frac{2P}{a}\right) + \frac{P}{a}w_1w_2 - (Q_1w_1 + Q_2w_2)$$

\subsection{Part B}
We can write the equation we got in the previous part as:

$$\Pi =  - (Q_1w_1 + Q_2w_2)  + \frac{1}{2}\left[ w_1\left\{ w_1\left(k-\frac{2P}{a}\right)+ \frac{P}{a}w_2\right\} +
w_2\left\{ w_2\left(k-\frac{2P}{a}\right)+ \frac{P}{a}w_1\right\}\right]$$

$$\Pi =
-\begin{bmatrix}w_1 & w_2\end{bmatrix}\begin{bmatrix}Q_1\\ Q_2\end{bmatrix} + \frac{1}{2}\begin{bmatrix}w_1 & w_2\end{bmatrix}\begin{bmatrix}
k-\frac{2P}{a} & \frac{P}{a}\\
\frac{P}{a} & k-\frac{2P}{a}\\
\end{bmatrix}\begin{bmatrix}w_1\\ w_2\end{bmatrix}
$$

By putting $w = \begin{bmatrix}w_1 & w_2\end{bmatrix}^T$,$q = \begin{bmatrix}Q_1 & Q_2\end{bmatrix}^T$ and $\mat{K_{tot}} = \begin{bmatrix}
k-\frac{2P}{a} & \frac{P}{a}\\
\frac{P}{a} & k-\frac{2P}{a}\\
\end{bmatrix}$, we will get 

$$\Pi = -\Vec{w}^T\Vec{q} + \frac{1}{2}\Vec{w}^T\mat{K}_{\text{tot}}\Vec{w}$$

\subsection{Part C}
If we open the system of equations in $\mat{K}_{\text{tot}}\Vec{w} = \Vec{q}$.

$$
\begin{bmatrix}
k-\frac{2P}{a} & \frac{P}{a}\\
\frac{P}{a} & k-\frac{2P}{a}\\
\end{bmatrix}\begin{bmatrix}w_1\\ w_2\end{bmatrix} = \begin{bmatrix}Q_1 \\ Q_2\end{bmatrix}
$$

Now, we know that k, P, a, Q\textsubscript{1},Q\textsubscript{2} are constants.


In Part B we got the Potential Energy of the system. For Equilibrium, we need to set the Net Force = 0. For this we need the force from the Potential Energy Equation. We partially differentiate the PE equation by both $w_1$ and $w_2$ to get two equations.

$$
\frac{d\Pi}{dw_1} = \frac{2w_1}{2}\left(k-\frac{2P}{a}\right) + \frac{Pw_2}{a} - Q_1$$
$$\frac{d\Pi}{dw_2} = \frac{2w_2}{2}\left(k-\frac{2P}{a}\right) + \frac{Pw_1}{a} - Q_2
$$

Setting $\frac{d\Pi}{dw_1}$ and $\frac{d\Pi}{dw_2}$ zero for Equilibrium Configuration,
$$w_1\left(k-\frac{2P}{a}\right) + \frac{Pw_2}{a} = Q_1 $$
$$w_2\left(k-\frac{2P}{a}\right) + \frac{Pw_1}{a} = Q_2 $$

We can write this as a Matrix.

$$
\begin{bmatrix}
k-\frac{2P}{a} & \frac{P}{a}\\
\frac{P}{a} & k-\frac{2P}{a}\\
\end{bmatrix}\begin{bmatrix}w_1\\ w_2\end{bmatrix} = \begin{bmatrix}Q_1 \\ Q_2\end{bmatrix}
$$

Which is the same as $\mat{K}_\text{tot} \Vec{w} = \Vec{q}$.

\subsection{Part D}

Putting the given values of $\Vec{\text{q}}$ and P, we get

$$w_1\left(k-\frac{2}{a}\frac{ka}{6}\right) + \frac{ka}{6}\frac{w_2}{a} = \frac{ka}{24} \text{  \hspace{0.6cm},\hspace{0.6cm} } w_2\left(k-\frac{2}{a}\frac{ka}{6}\right) + \frac{ka}{6}\frac{w_1}{a} = \frac{ka}{12} $$

$$w_1 - \frac{w_1}{3} + \frac{w_2}{6} = \frac{a}{24} \text{  \hspace{0.6cm},\hspace{0.6cm} } w_2-\frac{w_2}{3} + \frac{w_1}{6} = \frac{a}{12} $$


$$16w_1 + 4w_2 = a \text{  \hspace{0.6cm},\hspace{0.6cm} } 8w_2 + 2w_1 = a $$

$$\text{By solving the two equations we will get } w_1 = \frac{7a}{60} \text{ and } w_2 = \frac{a}{30}$$

\subsection{Part E}

For $\text{P} = \frac{ka}{6}\text{, we get }
\begin{bmatrix}
\frac{2k}{3} & \frac{k}{6}\\
\frac{k}{6} & \frac{2k}{3}
\end{bmatrix}
\text{, for which the eigenvalues are } \frac{5k}{6} \text{ and } \frac{k}{2}
$

For $\text{P} = \frac{2ka}{3}\text{, we get }
\begin{bmatrix}
-\frac{k}{3} & \frac{2k}{3}\\
\frac{2k}{3} & -\frac{k}{3}
\end{bmatrix}
\text{, for which the eigenvalues are } -k \text{ and } \frac{k}{3}
$

For $\text{P} = 2ka\text{, we get }
\begin{bmatrix}
-3k & 2k\\
2k & -3k
\end{bmatrix}
\text{, for which the eigenvalues are } -2-3k \text{ and } 2-3k
$




\section{Question}
\subsection{Part A}
% \begin{lstlisting}[language = Octave]
% S = [3/4 1/8 0 1/8; 1/2 1/2 0 0; 1/8 3/4 1/8 0; 0 1/2 1/2 0;
% 0 1/8 3/4 1/8; 0 0 1/2 1/2; 1/8 0 1/8 3/4; 1/2 0 0 1/2];
% X = [0 0; 0 1; 1 1; 1 0];
% P = S*X;
% scatter(X(:,1),X(:,2));
% hold on
% scatter(P(:,1),P(:,2));
% \end{lstlisting}

We form our $\mat{X}$ matrix by putting the vectors of the square as rows of the matrix. We will then get 

$$
\mat X = 
\begin{bmatrix}
0 & 0 \\
0 & 1 \\
1 & 1 \\
1 & 0 \\
\end{bmatrix}
$$

Multiplying S to it $A = SX$ gives us points for p\textsuperscript{1}

\begin{figure}[hbt!]
    \centering
    \begin{tikzpicture}[xscale=0.7,yscale=0.8]
    \begin{axis}
    [no markers,grid=both]
    \addplot coordinates {(0,0)(0,1)(1,1)(1,0)} \closedcycle;
    \end{axis}
    \end{tikzpicture} \hspace{0.3cm}
    \begin{tikzpicture}[xscale=0.7,yscale=0.8]
    \begin{axis}
    [no markers,grid=both]
    \addplot coordinates {(0.125,0.125)(0,0.5)(0.125,0.875)(0.5,1)(0.875,0.875)(1,0.5)(0.875,0.125)(0.5,0)(0.125,0.125)};
    \end{axis}
    \end{tikzpicture} \hspace{0.3cm}
    \begin{tikzpicture}[xscale=0.7,yscale=0.8]
    \begin{axis}
    [no markers,grid=both]
    \addplot coordinates {(0,0)(0,1)(1,1)(1,0)} \closedcycle;
    \addplot coordinates {(0.125,0.125)(0,0.5)(0.125,0.875)(0.5,1)(0.875,0.875)(1,0.5)(0.875,0.125)(0.5,0)(0.125,0.125)};
    \end{axis}
    \end{tikzpicture}
    \caption{Caption}
\end{figure}

\subsection{Part B}
\begin{wrapfigure}[8]{r}{6cm}
\centering
\vspace{-1cm}
\begin{tikzpicture}[xscale=0.7,yscale=0.8]
\begin{axis}
[no markers,grid=both]
\addplot coordinates {(0.125,0.125)(0,0.5)(0.125,0.875)(0.5,1)(0.875,0.875)(1,0.5)(0.875,0.125)(0.5,0)(0.125,0.125)};
\addplot coordinates {(0,0)(0,1)(1,1)(1,0)(0,0)};
\addplot coordinates{(0.1562,0.1562)(0.0625,0.3125)(0.0312,0.5000)(0.0625,0.6875)(0.1562,0.8438)(0.3125,0.9375)(0.5000,0.9688)(0.6875,0.9375)(0.8438,0.8438)(0.9375,0.6875)(0.9688,0.5000)(0.9375,0.3125)(0.8438,0.1562)(0.6875,0.0625)(0.5000,0.0312)(0.3125,0.0625)(0.1562,0.1562)};
\end{axis}
\end{tikzpicture}
\caption{Plot of $\Vec{p}^0$,$\Vec{p}^1$ \& $\Vec{p}^2$}
\end{wrapfigure}

We can see that the formulae for finding the points have 3/4 on the i\textsuperscript{th} element and 1/8 on the (i-1)\textsuperscript{th} and (i+1)\textsuperscript{th} elements. The elements rotate for out of bound value of i+1 or i-1. So, for $i=0$, (i-1)\textsuperscript{th} element will be the last one of the row. Now, as i goes to n, which is 8 in this case, we will get 16 rows and 8 columns. The 8 columns are for the 8 vectors we got from the first transformation of the unit square. Now, as i is incremented, the row only gets shifted towards the right. Same happens for the other formula where 1/2 is the coefficient of the i\textsuperscript{th} and (i+1)\textsuperscript{th} elements.
The Subdivision Matrix for getting $p^2$ is thus written as


\[ \hspace{-2cm}
 \begin{bmatrix} 
    3/4 & 1/8 & 0  & 0& 0 & 0 & 0 & 1/8 \\
    1/2 & 1/2 & 0 & 0 & 0 & 0 & 0 & 0\\
    1/8 & 3/4 & 1/8 & 0 & 0& 0 & 0 & 0\\
    0& 1/2 & 1/2 & 0 & 0 & 0 & 0 & 0\\
    0 & 1/8 & 3/4 & 1/8 & 0 & 0& 0 & 0\\
    0 & 0 & 1/2 & 1/2 & 0 & 0 & 0 & 0\\
    0 & 0 & 1/8 & 3/4 & 1/8 & 0 & 0& 0 \\
    0 & 0 & 0 & 1/2 & 1/2 & 0 & 0 & 0\\
    0 & 0 & 0 & 1/8 & 3/4 & 1/8 & 0 & 0\\
    0 & 0 & 0 & 0 & 1/2 & 1/2 & 0 & 0\\
    0 & 0 & 0 & 0 & 1/8 & 3/4 & 1/8 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1/2 & 1/2 & 0\\
    0 & 0 & 0 & 0 & 0 & 1/8 & 3/4 & 1/8\\
    0 & 0 & 0 & 0 & 0 & 0 & 1/2 & 1/2\\
    1/8 & 0 & 0 & 0 & 0 & 0 & 1/8 & 3/4\\
    1/2 & 0 & 0 & 0 & 0 & 0 & 0 & 1/2\\
\end{bmatrix}
 \]
\subsection{Part C}

The Shape smoothes out to form a multisided polygon whose number of vertices double on the application of every transformation and then smooths out into a circle, as can be anticipated from the obtained curve in Part B.

\subsection{Part D}

After repeatedly applying the $\Hat{S}$ Matrix on the vector of coordinates of the unit square, we get four points which appear to get closer and closer, and the overall shape of the curve appears to be smoothing out into a curve rather than straight lines.


\begin{figure}[hbt!]
    \centering
    \begin{tikzpicture}[xscale=0.7,yscale=0.8]
    \begin{axis}
    [title=p\textsuperscript{1} and p\textsuperscript{2},no markers,grid=both,legend style={at={(0,1)},anchor=north west}]
    \addplot coordinates {(0.5000, 0)(0.8750,0.1250)(1.0000,0.5000)(0.8750,0.8750)};
    \addplot coordinates {(0.6875, 0.0625)(0.8438, 0.1562)(0.9375,0.3125)(0.9688,
    0.5000)};
    \legend{$p^1$,$p^2$}
    \end{axis}
    \end{tikzpicture}\hspace{0.4cm}
    \begin{tikzpicture}[xscale=0.7,yscale=0.8]
    \begin{axis}
    [title=p\textsuperscript{2} and p\textsuperscript{3},no markers,grid=both,legend style={at={(0,1)},anchor=north west}]
    \addplot coordinates {(0.6875, 0.0625)(0.8438, 0.1562)(0.9375,0.3125)(0.9688,
    0.5000)};
    \addplot coordinates {(0.7656, 0.1094)(0.8359, 0.1641)(0.8906, 0.2344)(0.9297, 0.3164)};
    \legend{$p^2$,$p^3$}
    \end{axis}
    \end{tikzpicture}\hspace{0.4cm}
    \begin{tikzpicture}[xscale=0.7,yscale=0.8]
    \begin{axis}
    [title=p\textsuperscript{3} and p\textsuperscript{4},no markers,grid=both,legend style={at={(0,1)},anchor=north west}]
    \addplot coordinates {(0.7656, 0.1094)(0.8359, 0.1641)(0.8906, 0.2344)(0.9297, 0.3164)};
    \addplot coordinates {(0.8008, 0.1367)(0.8340, 0.1660)(0.8633, 0.1992)(0.8887, 0.2358)};
    \legend{$p^3$,$p^4$}
    \end{axis}
    \end{tikzpicture}
    \caption{Left to Right: Different levels of transformation by the $\Hat{S}$ Matrix}
\end{figure}

\subsection{Part E}
The EigenDecomposition is done by making a diagonal matrix $\Lambda$ of EigenValues and a Matrix Q which consists of the corresponding eigen vectors as columns. Then EigenDecomposition is given by $A = Q \Lambda Q^{-1}$.

$$
\underset{\Hat{S}}{
\begin{bmatrix}
    1/2 & 1/2 & 0   & 0  \\    
    1/8 & 3/4 & 1/8 & 0   \\    
     0  & 1/2 & 1/2 & 0   \\     
     0  & 1/8 & 3/4 & 1/8
\end{bmatrix}}
 = \underset{Q}{
\begin{bmatrix}
1 & -\frac{1}{2} & 0 & \frac{2}{11}\\
1 & 0 & 0 & -\frac{1}{11}\\
1 & \frac{1}{2} & 0 & \frac{2}{11}\\
1 & 1 & 1 & 1
\end{bmatrix}}\underset{\Lambda}{
\begin{bmatrix}
1 & 0 & 0 & 0\\
0 & \frac{1}{2} & 0 & 0\\
0 & 0 & \frac{1}{8} & 0\\
0 & 0 & 0 & \frac{1}{4}
\end{bmatrix}}\underset{Q^{-1}}{
\begin{bmatrix}\frac{1}{6}&\frac{2}{3}&\frac{1}{6}&0\\ -1&0&1&0\\ -1&3&-3&1\\ \frac{11}{6}&-\frac{11}{3}&\frac{11}{6}&0\end{bmatrix}}
$$
% \newpage

\subsection{Part F}

We know that taking power of Matrix is equivalent to taking power of its eigenvalues. We can exploit this fact to write the expression for $\Vec{p}^{l+1}$.

$$
\Vec{p}^{l+1} = \mat{\Hat{S}}^{l+1}\Vec{p}^{0}={Q}{\Lambda}^{l+1}Q^{-1}\Vec{p}^{0}
 = \underset{Q}{
\begin{bmatrix}
1 & -\frac{1}{2} & 0 & \frac{2}{11}\\
1 & 0 & 0 & -\frac{1}{11}\\
1 & \frac{1}{2} & 0 & \frac{2}{11}\\
1 & 1 & 1 & 1
\end{bmatrix}}\underset{\Lambda^{l+1}}{
\begin{bmatrix}
1 & 0 & 0 & 0\\
0 & \frac{1}{2} & 0 & 0\\
0 & 0 & \frac{1}{8} & 0\\
0 & 0 & 0 & \frac{1}{4}
\end{bmatrix}^{l+1}}\underset{Q^{-1}}{
\begin{bmatrix}\frac{1}{6}&\frac{2}{3}&\frac{1}{6}&0\\ -1&0&1&0\\ -1&3&-3&1\\ \frac{11}{6}&-\frac{11}{3}&\frac{11}{6}&0\end{bmatrix}}
\underset{\Vec{p}^{0}}{\begin{bmatrix}0&0\\ 1&0\\ 1&1\\ 0&1\end{bmatrix}}
$$



\subsection{Part G}
The original matrix of sorted eigenvalues is $\Lambda$, let's call the eigenvalue matrix with the highest eigenvalue dropped as $\Lambda^{'}$. Now, if we find $\Vec{p}^{l+1}$ for both eigenvalue matrices, we will get

\begin{wrapfigure}[8]{R}{6cm}
\centering
\begin{tikzpicture}[xscale=0.7,yscale=0.7]
\begin{axis}[no markers,legend style={at={(0,1)},anchor=north west},grid=both]
\addplot coordinates {(-1/3,-1/6)(1/24,-1/24)(1/6,1/3)(1/24,17/24)};
\addplot coordinates {(1/2,0)(7/8,1/8)(1,1/2)(7/8,7/8)};
\legend{$\Lambda^{'}$,$\Lambda$}
\end{axis}
\end{tikzpicture}
\caption{Curves for $\Lambda$ \& $\Lambda^{'}$}
\end{wrapfigure}

$$
\begin{bmatrix}
1&-\frac{1}{2}&\frac{2}{11}&0\\ 
1&0&-\frac{1}{11}&0\\
1&\frac{1}{2}&\frac{2}{11}&0\\
1&1&1&1
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0 & 0\\
0 & \frac{1}{2} & 0 & 0\\
0 & 0 & \frac{1}{4} & 0\\
0 & 0 & 0 & \frac{1}{8}
\end{bmatrix}
\begin{bmatrix}\frac{1}{6}&\frac{2}{3}&\frac{1}{6}&0\\ -1&0&1&0\\ \frac{11}{6}&-\frac{11}{3}&\frac{11}{6}&0\\ -1&3&-3&1\end{bmatrix}
{\begin{bmatrix}0&0\\ 1&0\\ 1&1\\ 0&1\end{bmatrix}}=
\begin{bmatrix}-\frac{1}{3}&-\frac{1}{6}\\ \frac{1}{24}&-\frac{1}{24}\\ \frac{1}{6}&\frac{1}{3}\\ \frac{1}{24}&\frac{17}{24}\end{bmatrix}
$$

$$
\begin{bmatrix}
1&-\frac{1}{2}&\frac{2}{11}&0\\ 
1&0&-\frac{1}{11}&0\\
1&\frac{1}{2}&\frac{2}{11}&0\\
1&1&1&1
\end{bmatrix}
\begin{bmatrix}
0 & 0 & 0 & 0\\
0 & \frac{1}{2} & 0 & 0\\
0 & 0 & \frac{1}{4} & 0\\
0 & 0 & 0 & \frac{1}{8}
\end{bmatrix}
\begin{bmatrix}\frac{1}{6}&\frac{2}{3}&\frac{1}{6}&0\\ -1&0&1&0\\ \frac{11}{6}&-\frac{11}{3}&\frac{11}{6}&0\\ -1&3&-3&1\end{bmatrix}
{\begin{bmatrix}0&0\\ 1&0\\ 1&1\\ 0&1\end{bmatrix}}=
\begin{bmatrix}\frac{1}{2}&0\\ \frac{7}{8}&\frac{1}{8}\\ 1&\frac{1}{2}\\ \frac{7}{8}&\frac{7}{8}\end{bmatrix}
$$

We can plot these two sets of vectors. Both the curves are denoted by their respective eigenvalue matrices. We can see that the resultant vectors for $\Lambda^{'}$ have the same shape as the original ones and are only shifted by $(\frac{1}{6},\frac{1}{6})$. Adding $(1/6,1/6)$ to all vectors of $\Lambda^{'}$'s curve can produce the original curve. Hence after finding this out we no longer need our highest eigenvalue and it can be dropped. As for dropping $p_2$ and $p_3$, we know that they are very small and for higher value of l, they will become more and more small such that they will tend to become 0. Hence they can be dropped for large values of l.


    

\section{Question}

{\centering
$\underset{m \times n}{A} = \underset{m \times m}{U}\cdot \underset{m \times n}{\Sigma}\cdot \underset{n \times n}{V^T}$

}

Since we have been given that the dimensions of $V^T$ are n = 4 which will be the number of columns in A. We also know that there are 2 values in the $\Sigma$ Matrix. Which means that the $\Sigma$ Matrix must have $m=2$ rows. Also from the multiplication relation above, we can deduce that $\Sigma$ must have $n = 4$ columns. So, $\Sigma$ will have dimensions $2 \times 4$.
\subsection{Part A}
Dimension of $dim(C(A^T)) = m = r$, which is 2.
\subsection{Part B}
Dimension of $dim(N(A^T)) = m - r$, which is 0. Due to $\mat{A}$ being Full Row Rank.
\subsection{Part C}
From the multiplication relation above, the deduced dimensions of U and A are $2\times2$ and $2\times 4$ respectively.
\subsection{Part D}
Since $\Sigma$ is $2\times4$ and its a diagonal with $\sigma_1 = \sigma_2 = \sqrt{2}$, the matrix is 
$$
\Sigma =
\begin{bmatrix}
\sqrt{2} & 0 & 0 & 0 \\
 0 &\sqrt{2} & 0 & 0 \\
\end{bmatrix}
$$

\subsection{Part E}
If The Matrix K is multiplied by 8, only the singular values of K will be multiplied by 8. 
For K\textsuperscript{-1}, U and V will switch places and the $\Sigma$ Matrix will be inverted.
For K\textsuperscript{T} the $\Sigma$ will remain the same, however  U and V will switch their places.
$$\texttt{svd(}K\texttt{)} = U\cdot \Sigma\cdot V^T$$
$$\texttt{svd(}8K\texttt{)} = U\cdot (8\Sigma)\cdot V^T$$
$$\texttt{svd(}K^{-1}\texttt{)} = V\cdot \Sigma^{-1}\cdot U^T$$
$$\texttt{svd(}K^{T}\texttt{)} =  V\cdot \Sigma\cdot U^T$$



\section{Question}

\noindent a) A Parallelopiped

\noindent b) The Matrix must be orthogonal and must be full rank.

\noindent c) The Matrix must have exactly 1 pivot or rank.

\noindent d) The Matrix must have exactly 2 pivots or rank.

\noindent e) If Determinant of Matrix is 1.

\noindent d) All are Linear.

\end{document}